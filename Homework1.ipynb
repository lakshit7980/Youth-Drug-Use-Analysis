{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3856010",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_csv('/Users/lakshitgupta/Library/CloudStorage/OneDrive-SeattleUniversity/Quater3/Machine Learning-2/Written Homeworks/youth_data.csv')\n",
    "print(dfo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6a7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "substance_cols = [\n",
    "    'iralcfy', 'irmjfy', 'ircigfm', 'IRSMKLSS30N', 'iralcfm', 'irmjfm',\n",
    "    'ircigage', 'irsmklsstry', 'iralcage', 'irmjage',\n",
    "    'mrjflag', 'alcflag', 'tobflag',\n",
    "    'alcydays', 'mrjydays', 'alcmdays', 'mrjmdays', 'cigmdays', 'smklsmdays'\n",
    "]\n",
    "\n",
    "demographic_cols = [\n",
    "    'irsex', 'NEWRACE2', 'HEALTH2', 'eduschlgo', 'EDUSCHGRD2',\n",
    "    'eduskpcom', 'imother', 'ifather', 'income', 'govtprog',\n",
    "    'POVERTY3', 'PDEN10', 'COUTYP4'\n",
    "]\n",
    "\n",
    "# Load data and select columns of interest\n",
    "df_youth = dfo.loc[:, 'schfelt':'rlgfrnd']  \n",
    "df_substance = dfo[substance_cols]\n",
    "df_demog = dfo[demographic_cols]\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df = pd.concat([df_substance, df_youth, df_demog], axis=1)\n",
    "\n",
    "# Fix metadata\n",
    "\n",
    "# Define unordered and ordered factor columns\n",
    "unordered_factor_cols = (\n",
    "    list(df_youth.columns) +\n",
    "    ['mrjflag', 'alcflag', 'tobflag'] +\n",
    "    ['irsex', 'NEWRACE2', 'eduschlgo', 'imother', 'ifather', 'govtprog', 'PDEN10', 'COUTYP4']\n",
    ")\n",
    "ordered_factor_cols = ['EDUSCHGRD2', 'HEALTH2', 'POVERTY3', 'income']\n",
    "\n",
    "# Convert to factors\n",
    "df[unordered_factor_cols] = df[unordered_factor_cols].astype('category')  # Unordered factors\n",
    "for col in ordered_factor_cols:\n",
    "    df[col] = pd.Categorical(df[col], ordered=True)  # Ordered factors\n",
    "\n",
    "# Define variable labels as a dictionary\n",
    "variable_labels = {\n",
    "    'iralcfy': 'Alcohol frequency past year',\n",
    "    'irmjfy': 'Marijuana frequency past year',\n",
    "    # and so on...\n",
    "}\n",
    "\n",
    "# Assign labels to DataFrame columns\n",
    "df.columns = pd.Index(variable_labels.get(col, col) for col in df.columns)\n",
    "\n",
    "# Note: You can access the labeled data using df.columns\n",
    "\n",
    "youth_experience_cols = df_youth.columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isna().sum().sum()\n",
    "print(f\"Number of missing values: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ed440",
   "metadata": {},
   "outputs": [],
   "source": [
    "youth_experience_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_substance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dfd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demog.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a06df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "missing_values = df.isna().sum().sum()\n",
    "print(f\"Number of missing values after dropping: {missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['EDUSCHGRD2'].isin([98, 99])]\n",
    "\n",
    "# Filter out rows where eduskpcom is 94, 97, 98, or 99\n",
    "df = df[~df['eduskpcom'].isin([94, 97, 98, 99])]\n",
    "\n",
    "# Filter out rows where imother is 3 or 4\n",
    "df = df[~df['imother'].isin([3, 4])]\n",
    "\n",
    "# Filter out rows where ifather is 3 or 4\n",
    "df = df[~df['ifather'].isin([3, 4])]\n",
    "\n",
    "# Filter out rows where PDEN10 is 3\n",
    "df = df[df['PDEN10'] != 3]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc3f19",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "## Alcohol - 'alcflag' \n",
    "## Alcohol ever used (0=never, 1=ever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youthExp = df[youth_experience_cols]\n",
    "df_demographic = df[demographic_cols]\n",
    "ALCFLAG = df[['alcflag']]\n",
    "\n",
    "# Combining into a new DataFrame\n",
    "df_New = pd.concat([df_youthExp, df_demographic, ALCFLAG], axis=1)\n",
    "\n",
    "print(df_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_New.drop(columns=['alcflag'])\n",
    "y = df_New['alcflag'] \n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "\n",
    "print(\"Training set dimensions:\", X_train.shape)\n",
    "print(\"Test set dimensions:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c2712",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14418494",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=1)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70, 100))\n",
    "\n",
    "# Plotting the decision tree\n",
    "plot_tree(tree_model,\n",
    "          filled=True,\n",
    "          feature_names=X_train.columns.tolist(),\n",
    "          class_names=['No', 'Yes'],\n",
    "          label='all',\n",
    "          fontsize=24)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting feature importances\n",
    "feature_importance = tree_model.feature_importances_\n",
    "\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sortting the DataFrame by importance values in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "# Display the top 15 features\n",
    "print(\"Top 15 Feature Importance:\")\n",
    "print(top_10_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, tree_pred)\n",
    "\n",
    "# Accuracy\n",
    "Decaccuracy = accuracy_score(y_test, tree_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"Accuracy:\", Decaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529378f",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b950e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "param_grid = {'max_leaf_nodes': range(2,20)}\n",
    "\n",
    "# Create GridSearchCV \n",
    "grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best estimator\n",
    "best_tree_model = grid_search.best_estimator_\n",
    "\n",
    "pruned_tree_pred = best_tree_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "pruned_cm = confusion_matrix(y_test, pruned_tree_pred)\n",
    "\n",
    "# Accuracy\n",
    "pruned_accuracy = accuracy_score(y_test, pruned_tree_pred)\n",
    "\n",
    "print(\"max_leaf_nodes:\", best_tree_model.max_leaf_nodes)\n",
    "print(\"Confusion Matrix after Pruning:\")\n",
    "print(pruned_cm)\n",
    "print(\"Accuracy after Pruning:\", pruned_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_list = X_train.columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plotting the pruned decision tree\n",
    "plot_tree(best_tree_model, filled=True, feature_names=feature_names_list, class_names=[\"No\", \"Yes\"], fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_leaf_nodes_range = range(2, 20)\n",
    "accuracies = []\n",
    "num_leaf_nodes = []\n",
    "\n",
    "for leaf_nodes in max_leaf_nodes_range:\n",
    "    tree_model = DecisionTreeClassifier(max_leaf_nodes=leaf_nodes, random_state=1)\n",
    "    \n",
    "    accuracy = np.mean(cross_val_score(tree_model, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    num_leaf_nodes.append(leaf_nodes)\n",
    "\n",
    "Prunmax_accuracy = max(accuracies)\n",
    "corresponding_num_leaf_nodes = num_leaf_nodes[accuracies.index(Prunmax_accuracy)]\n",
    "\n",
    "print('Maximum Accuracy:', Prunmax_accuracy)\n",
    "print('Corresponding Number of Leaf Nodes:', corresponding_num_leaf_nodes)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_leaf_nodes, accuracies, marker='o', linestyle='-')\n",
    "plt.xlabel('Number of Leaf Nodes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Number of Leaf Nodes')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_tree_model.feature_importances_\n",
    "\n",
    "# Importances along with feature names\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_features = feature_importance_df.head(10)  \n",
    "# Display the top features\n",
    "print(\"Top Features:\")\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191a642",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aef225",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_model = RandomForestClassifier(n_estimators=100, max_features=60, random_state=1)\n",
    "\n",
    "# Fitting the Random Forest classifier\n",
    "bag_model.fit(X_train, y_train)\n",
    "\n",
    "yhat_bag = bag_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "Bagaccuracy = accuracy_score(y_test, yhat_bag)\n",
    "print('\\nAccuracy:', Bagaccuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Importances from the Random Forest model\n",
    "feature_importances_bag = bag_model.feature_importances_\n",
    "\n",
    "feature_importance_bag_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances_bag})\n",
    "\n",
    "feature_importance_bag_df = feature_importance_bag_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_features_bag = feature_importance_bag_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features_bag['Feature'], top_features_bag['Importance'], color='blue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Variable Importance for Consumption of Alcohol')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c09c6f",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29e59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "random_model = RandomForestClassifier(n_estimators=500, max_features=30, random_state=1)\n",
    "\n",
    "# Fit the Random Forest classifier to the training data\n",
    "random_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "yhat_rf = random_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "Ranaccuracy = accuracy_score(y_test, yhat_rf)\n",
    "print('\\nAccuracy:', Ranaccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63312ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = random_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "print(\"Top 10 Feature Importance:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05646dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry_values = [1, 25, 45, 55, 60]\n",
    "accuracy_values = []\n",
    "\n",
    "for mtry in mtry_values:\n",
    "    # Initializing and fit Random Forest with current mtry value\n",
    "    rf_model = RandomForestClassifier(n_estimators=500, max_features=mtry, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    yhat_test = rf_model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, yhat_test)\n",
    "    accuracy_values.append(accuracy)\n",
    "\n",
    "print('Accuracy Values:', accuracy_values)\n",
    "\n",
    "# Finding the index of the highest accuracy value\n",
    "max_accuracy_index = accuracy_values.index(max(accuracy_values))\n",
    "Ranhighest_accuracy = accuracy_values[max_accuracy_index]\n",
    "corresponding_mtry = mtry_values[max_accuracy_index]\n",
    "\n",
    "print('Highest Accuracy:', Ranhighest_accuracy)\n",
    "print('Corresponding mtry:', corresponding_mtry)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mtry_values, accuracy_values, marker='o', linestyle='-')\n",
    "plt.xlabel('mtry')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. mtry')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898223d",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fed48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(0.1, 0.21, 0.02)\n",
    "\n",
    "# Gradient Boosting model with different shrinkage values\n",
    "gbm_models = []\n",
    "accuracy_values = []\n",
    "\n",
    "for lam1 in vals:\n",
    "    boosting_model = GradientBoostingClassifier(n_estimators=1000, learning_rate=lam1, random_state=1)\n",
    "    boosting_model.fit(X_train, y_train)\n",
    "    yhat_test = boosting_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, yhat_test)\n",
    "    gbm_models.append(boosting_model)\n",
    "    accuracy_values.append(accuracy)\n",
    "  \n",
    "# Test set accuracy vs. learning rate\n",
    "plt.plot(vals, accuracy_values, marker='o', linestyle='-')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. learning_rate')\n",
    "plt.show()\n",
    "\n",
    "# Finding the highest accuracy and its corresponding learning rate\n",
    "max_accuracy_index = np.argmax(accuracy_values)\n",
    "Boosthighest_accuracy = accuracy_values[max_accuracy_index]\n",
    "corresponding_learning_rate = vals[max_accuracy_index]\n",
    "\n",
    "print(\"Highest Accuracy:\", Boosthighest_accuracy)\n",
    "print(\"Corresponding Learning Rate:\", corresponding_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e70e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = []\n",
    "\n",
    "for model in gbm_models:\n",
    "    # Feature importances from Boosting\n",
    "    importances = model.feature_importances_\n",
    "    feature_importances.append(importances)\n",
    "\n",
    "\n",
    "average_importances = np.mean(feature_importances, axis=0)\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': average_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_10_features = importance_df.head(10)\n",
    "\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffd757",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = {\n",
    "    \"Model\": [\"Decision Tree\", \"Pruned Decision Tree\", \"Bagging\", \"Random Forest\", \"Boosting\"],\n",
    "    \"Accuracy\": [Decaccuracy, Prunmax_accuracy, Bagaccuracy, Ranhighest_accuracy, Boosthighest_accuracy]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the accuracy data\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "\n",
    "# Set the style for the DataFrame\n",
    "styled_accuracy_df = accuracy_df.style.hide_index().set_caption(\"Model Accuracy\")\n",
    "\n",
    "# Apply formatting to the accuracy values\n",
    "styled_accuracy_df = styled_accuracy_df.format({\"Accuracy\": \"{:.2%}\"})\n",
    "\n",
    "# Display the styled accuracy DataFrame\n",
    "styled_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bedbc9",
   "metadata": {},
   "source": [
    "## Multi Class Classification\n",
    "## Marijuana - 'mrjmdays'\n",
    "## Number of days of marijuana in past month (1-4 categories, 5=none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youthExp1 = df[youth_experience_cols]\n",
    "df_demographic1 = df[demographic_cols]\n",
    "MRJMDAYS = df[['mrjmdays']]\n",
    "\n",
    "df_Multi = pd.concat([df_youthExp1, df_demographic1, MRJMDAYS], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Multi.drop(columns=['mrjmdays']) \n",
    "y = df_Multi['mrjmdays']  \n",
    "\n",
    "# Training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3a666f",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_modelNew = DecisionTreeClassifier(random_state=1)\n",
    "tree_modelNew.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2869a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70, 100))\n",
    "\n",
    "\n",
    "plot_tree(tree_modelNew,\n",
    "          filled=True,\n",
    "          feature_names=X_train.columns.tolist(),\n",
    "          label='all',\n",
    "          fontsize=24)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = tree_modelNew.feature_importances_\n",
    "\n",
    "# Feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "# Displaying the top 10 features\n",
    "print(\"Top 10 Feature Importance:\")\n",
    "print(top_10_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_predNew = tree_modelNew.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, tree_predNew)\n",
    "Decaccuracy1 = accuracy_score(y_test, tree_predNew)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"Accuracy:\", Decaccuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3588dcc",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid\n",
    "param_grid = {'max_leaf_nodes': range(2,20)}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=tree_modelNew, param_grid=param_grid, cv=5,scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_tree_modelNew = grid_search.best_estimator_\n",
    "\n",
    "pruned_tree_predNew = best_tree_modelNew.predict(X_test)\n",
    "pruned_cmNew = confusion_matrix(y_test, pruned_tree_predNew)\n",
    "pruned_accuracy_new = accuracy_score(y_test, pruned_tree_predNew)\n",
    "\n",
    "print(\"max_leaf_nodes:\", best_tree_modelNew.max_leaf_nodes)\n",
    "print(\"Confusion Matrix after Pruning:\")\n",
    "print(pruned_cmNew)\n",
    "print(\"Accuracy after Pruning:\", pruned_accuracy_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_listNew = X_train.columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Pruned decision tree\n",
    "plot_tree(best_tree_modelNew, filled=True, feature_names=feature_names_listNew, fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a433dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_leaf_nodes_range = range(2, 20)\n",
    "\n",
    "accuracies = []\n",
    "num_leaf_nodes = []\n",
    "\n",
    "for leaf_nodes in max_leaf_nodes_range:\n",
    "    tree_modelNew = DecisionTreeClassifier(max_leaf_nodes=leaf_nodes, random_state=1)\n",
    "    \n",
    "    accuracy = np.mean(cross_val_score(tree_modelNew, X_train, y_train, cv=5, scoring='accuracy'))\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    num_leaf_nodes.append(leaf_nodes)\n",
    "\n",
    "Prunmax_accuracy1 = max(accuracies)\n",
    "corresponding_num_leaf_nodes = num_leaf_nodes[accuracies.index(Prunmax_accuracy1)]\n",
    "\n",
    "print('Maximum Accuracy:', Prunmax_accuracy1)\n",
    "print('Corresponding Number of Leaf Nodes:', corresponding_num_leaf_nodes)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_leaf_nodes, accuracies, marker='o', linestyle='-')\n",
    "plt.xlabel('Number of Leaf Nodes')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Number of Leaf Nodes')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba693497",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_tree_modelNew.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 5 features\n",
    "top_features = feature_importance_df.head(5)  \n",
    "\n",
    "print(\"Top Features:\")\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdfdb8f",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_model = RandomForestClassifier(n_estimators=100, max_features=60, random_state=1)\n",
    "bag_model.fit(X_train, y_train)\n",
    "\n",
    "yhat_bag = bag_model.predict(X_test)\n",
    "\n",
    "Bagaccuracy1 = accuracy_score(y_test, yhat_bag)\n",
    "print('\\nAccuracy:', Bagaccuracy1)\n",
    "\n",
    "# Feature importances from the Random Forest model\n",
    "feature_importances_bag = bag_model.feature_importances_\n",
    "\n",
    "feature_importance_bag_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances_bag})\n",
    "\n",
    "feature_importance_bag_df = feature_importance_bag_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 variables\n",
    "top_features_bag = feature_importance_bag_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features_bag['Feature'], top_features_bag['Importance'], color='blue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Variable Importance for Consumption of marijuana in past month')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f168e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "random_modelNew = RandomForestClassifier(n_estimators=500, max_features=30, random_state=1)\n",
    "\n",
    "# Fit the Random Forest classifier to the training data\n",
    "random_modelNew.fit(X_train, y_train)\n",
    "\n",
    "yhat_rf = random_modelNew.predict(X_test)\n",
    "\n",
    "Ranaccuracy1 = accuracy_score(y_test, yhat_rf)\n",
    "print('\\nAccuracy:', Ranaccuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d18e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "feature_importance = random_modelNew.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "print(\"Top 10 Feature Importance:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef531cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry_values = [1, 25, 45, 55, 60]\n",
    "accuracy_values = []\n",
    "\n",
    "for mtry in mtry_values:\n",
    "    rf_model = RandomForestClassifier(n_estimators=500, max_features=mtry, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    yhat_test = rf_model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, yhat_test)\n",
    "    accuracy_values.append(accuracy)\n",
    "\n",
    "# Finding the highest accuracy and its corresponding mtry value\n",
    "Ranmax_accuracy1 = max(accuracy_values)\n",
    "corresponding_mtry = mtry_values[accuracy_values.index(Ranmax_accuracy1)]\n",
    "\n",
    "print('Highest Accuracy:', Ranmax_accuracy1)\n",
    "print('Corresponding mtry:', corresponding_mtry)\n",
    "\n",
    "# Plot Accuracy vs. mtry\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mtry_values, accuracy_values, marker='o', linestyle='-')\n",
    "plt.xlabel('mtry')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. mtry')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d6528",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(0.1, 0.21, 0.01)\n",
    "\n",
    "# Gradient Boosting models with different shrinkage values\n",
    "gbm_models = []\n",
    "accuracy_values = []\n",
    "\n",
    "for lam1 in vals:\n",
    "    boosting_model = GradientBoostingClassifier(n_estimators=1000, learning_rate=lam1, random_state=1)\n",
    "    boosting_model.fit(X_train, y_train)\n",
    "    yhat_test = boosting_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, yhat_test)\n",
    "    gbm_models.append(boosting_model)\n",
    "    accuracy_values.append(accuracy)\n",
    "  \n",
    "# Test set accuracy vs. learning rate\n",
    "plt.plot(vals, accuracy_values, marker='o', linestyle='-')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. learning_rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Finding the highest accuracy and its corresponding learning rate\n",
    "Boostmax_accuracy1 = max(accuracy_values)\n",
    "corresponding_learning_rate = vals[accuracy_values.index(Boostmax_accuracy1)]\n",
    "\n",
    "print('Highest Accuracy:', Boostmax_accuracy1)\n",
    "print('Corresponding Learning Rate:', corresponding_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df63fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_boosting_model = GradientBoostingClassifier(n_estimators=1000, learning_rate=corresponding_learning_rate, random_state=1)\n",
    "best_boosting_model.fit(X_train, y_train)\n",
    "\n",
    "# Access feature importances\n",
    "feature_importance = best_boosting_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "# Display the top 10 features\n",
    "print(\"Top 10 Feature Importance:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2599ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data = {\n",
    "    \"Model\": [\"Decision Tree\", \"Pruned Decision Tree\", \"Bagging\", \"Random Forest\", \"Boosting\"],\n",
    "    \"Accuracy\": [Decaccuracy1, Prunmax_accuracy1, Bagaccuracy, Ranmax_accuracy1, Boostmax_accuracy1]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the accuracy data\n",
    "accuracy_df = pd.DataFrame(accuracy_data)\n",
    "\n",
    "# Set the style for the DataFrame\n",
    "styled_accuracy_df = accuracy_df.style.hide_index().set_caption(\"Model Accuracy\")\n",
    "\n",
    "# Apply formatting to the accuracy values\n",
    "styled_accuracy_df = styled_accuracy_df.format({\"Accuracy\": \"{:.2%}\"})\n",
    "\n",
    "# Display the styled accuracy DataFrame\n",
    "styled_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7be5cf",
   "metadata": {},
   "source": [
    "## Regression\n",
    "## Tobacco - 'irsmklsstry'\n",
    "## Smokeless tobacco age of first use (1-70), 991=never used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youthExp = df[youth_experience_cols]\n",
    "df_demographic = df[demographic_cols]\n",
    "IRSMKLSSTRY= df[['irsmklsstry']]\n",
    "\n",
    "df_Reg = pd.concat([df_youthExp, df_demographic, IRSMKLSSTRY], axis=1)\n",
    "df_Reg = df_Reg[df_Reg['irsmklsstry'] != 991]\n",
    "\n",
    "print(df_Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38458aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_Reg.drop(columns=['irsmklsstry'])\n",
    "y = df_Reg['irsmklsstry']  \n",
    "\n",
    "# Training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "print(\"Training set dimensions:\", X_train.shape)\n",
    "print(\"Test set dimensions:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526deb6",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "Reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12605713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(70, 100))\n",
    "\n",
    "plot_tree(Reg_model,\n",
    "          filled=True,\n",
    "          feature_names=X_train.columns.tolist(),\n",
    "          fontsize=24)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = Reg_model.feature_importances_\n",
    "\n",
    "# Feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "print(\"Top 10 Feature Importance:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_pred_new = Reg_model.predict(X_test)\n",
    "\n",
    "# Test error rate\n",
    "MSE = ((y_test - Reg_pred_new)**2).mean()\n",
    "print(\"Test Error Rate:\", MSE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab145b0",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_leaf_nodes': range(2, 20)}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=Reg_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_tree_model = grid_search.best_estimator_\n",
    "\n",
    "# Best max_leaf_nodes value\n",
    "print(\"Best max_leaf_nodes value:\", best_tree_model.max_leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_leaf_nodes_range = range(2, 20)\n",
    "\n",
    "num_trees = []\n",
    "mse_values = []\n",
    "\n",
    "for max_leaf_nodes in max_leaf_nodes_range:\n",
    "    \n",
    "    regressor = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n",
    "    mse_scores = -cross_val_score(regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    avg_mse = mse_scores.mean()\n",
    "\n",
    "    num_trees.append(max_leaf_nodes)\n",
    "    mse_values.append(avg_mse)\n",
    "    \n",
    "prunmin_mse = min(mse_values)\n",
    "corresponding_num_trees = num_trees[mse_values.index(prunmin_mse)]\n",
    "\n",
    "print('Minimum MSE:', prunmin_mse)\n",
    "print('Corresponding Number of Trees (max_leaf_nodes):', corresponding_num_trees)\n",
    "\n",
    "# MSE vs number of trees\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_trees, mse_values, marker='o')\n",
    "plt.title('MSE vs Number of Trees')\n",
    "plt.xlabel('Number of Trees (max_leaf_nodes)')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_listNew = X_train.columns.tolist()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plot_tree(best_tree_model, filled=True, feature_names=feature_names_listNew, fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb012a3",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_modelReg = RandomForestRegressor(n_estimators=100, max_features=60, random_state=1)\n",
    "\n",
    "bag_modelReg.fit(X_train, y_train)\n",
    "\n",
    "yhat_bagReg = bag_modelReg.predict(X_test)\n",
    "\n",
    "# Calculating the test MSE\n",
    "Bagtest_mse = mean_squared_error(y_test, yhat_bagReg)\n",
    "print('\\nTest MSE:', Bagtest_mse)\n",
    "\n",
    "feature_importances_bagReg = bag_modelReg.feature_importances_\n",
    "\n",
    "feature_importance_bagReg_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances_bagReg})\n",
    "\n",
    "feature_importance_bagReg_df = feature_importance_bagReg_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select the top 10 variables\n",
    "top_features_bagReg = feature_importance_bagReg_df.head(10)\n",
    "\n",
    "# Plot variable importance of different variables\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features_bagReg['Feature'], top_features_bagReg['Importance'], color='blue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Variable Importance for Regression')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cc9b9",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82786e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = RandomForestRegressor(n_estimators=500, max_features=30, random_state=1)\n",
    "\n",
    "random_model.fit(X_train, y_train)\n",
    "\n",
    "# Test set\n",
    "yhat_rf = random_model.predict(X_test)\n",
    "\n",
    "# Test MSE\n",
    "test_mse = mean_squared_error(y_test, yhat_rf)\n",
    "print('\\nTest MSE:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances from the Random Forest model\n",
    "feature_importance = random_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "feature_name_mapping = {\n",
    "    'EDUSCHGRD2': 'Grade',\n",
    "    'talkprob': 'Talks_about_problems',\n",
    "    'eduskpcom': 'Skipped_school_days',\n",
    "    'DRPRVME3': 'Seen_prevention_message',\n",
    "    'FRDADLY2': 'Friends_view_on_drinking',\n",
    "    'NEWRACE2': 'Race/Hispanicity',\n",
    "    'YOATTAK2': 'Attacked_with_intent',\n",
    "    'rlgattd': 'Religious_service_attendance',\n",
    "    'HEALTH2': 'Health_status',\n",
    "    'COUTYP4': 'County_type'\n",
    "}\n",
    " \n",
    "# Convert the original feature names to their descriptive equivalents\n",
    "readable_features = [feature_name_mapping[f] for f in top_10_features['Feature']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(readable_features, top_10_features['Importance'], color='blue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Variables')\n",
    "plt.title('Variable Importance for Regression')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtry_values = [1, 25, 45, 55, 60]\n",
    "error_rates = []\n",
    "\n",
    "for mtry in mtry_values:\n",
    "    rf_model = RandomForestRegressor(n_estimators=500, max_features=mtry, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    yhat_test = rf_model.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, yhat_test)\n",
    "    error_rates.append(test_mse)\n",
    "\n",
    "# Error rates\n",
    "print('Error Rates:', error_rates)\n",
    "\n",
    "sorted_error_rates = sorted(error_rates)\n",
    "second_min_mse = sorted_error_rates[1]\n",
    "\n",
    "# Find the corresponding mtry value for the second smallest MSE\n",
    "index_second_min_mse = error_rates.index(second_min_mse)\n",
    "corresponding_mtry_second_min_mse = mtry_values[index_second_min_mse]\n",
    "\n",
    "print('Second Smallest MSE:', second_min_mse)\n",
    "print('Corresponding mtry value for the Second Smallest MSE:', corresponding_mtry_second_min_mse)\n",
    "\n",
    "# Error rate vs. mtry\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mtry_values, error_rates, marker='o', linestyle='-')\n",
    "plt.xlabel('mtry')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.title('Test MSE vs. mtry')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c956dde",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299c035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(0.1, 0.21, 0.01)\n",
    "\n",
    "# Training Gradient Boosting model with different shrinkage values\n",
    "boosting_models = []\n",
    "test_error_rates = []\n",
    "\n",
    "for lam1 in vals:\n",
    "    boosting_model = GradientBoostingRegressor(n_estimators=1000, learning_rate=lam1, random_state=1)\n",
    "    boosting_model.fit(X_train, y_train)\n",
    "    yhat_test = boosting_model.predict(X_test)\n",
    "    test_mse = mean_squared_error(y_test, yhat_test)\n",
    "    \n",
    "    boosting_models.append(boosting_model)\n",
    "    test_error_rates.append(test_mse)\n",
    "    \n",
    "Boostmin_test_mse = min(test_error_rates)\n",
    "corresponding_learning_rate = vals[test_error_rates.index(Boostmin_test_mse)]\n",
    "\n",
    "print('Minimum Test MSE:', Boostmin_test_mse)\n",
    "print('Corresponding Learning Rate:', corresponding_learning_rate)\n",
    "\n",
    "# Error rates vs. learning rate\n",
    "plt.plot(vals, test_error_rates, marker='o', linestyle='-')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Test MSE')\n",
    "plt.title('Test MSE vs. learning_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3e0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_learning_rate = vals[np.argmin(test_error_rates)]\n",
    "best_boosting_model = GradientBoostingRegressor(n_estimators=1000, learning_rate=best_learning_rate, random_state=1)\n",
    "best_boosting_model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = best_boosting_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importance})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "print(\"Top 10 Feature Importance:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44af62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_data = {\n",
    "    \"Model\": [\"Decision Tree\", \"Pruned Decision Tree\", \"Bagging\", \"Random Forest\", \"Boosting\"],\n",
    "    \"Test MSE\": [MSE, prunmin_mse, Bagtest_mse, second_min_mse, Boostmin_test_mse]\n",
    "}\n",
    "\n",
    "mse_df = pd.DataFrame(mse_data)\n",
    "styled_mse_df = mse_df.style.hide_index().set_caption(\"Model MSE\")\n",
    "styled_mse_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311dd6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
